消息队列的使用场景有哪些
    1.做秒杀活动的时候,会发生短时间内出现爆发式的用户请求
    如果不采取相关措施,会导致服务器忙不过来,响应超时等问题,轻则服务器假死,重则服务器直接宕机
    2.系统解耦,可以把系统的业务功能模块化,实现系统之间的解耦
    3.日志分析,当用户请求时,先处理用户请求再记录日志,使用MQ对消息进行采集和转发
    而前台用户也需要等待日志完成之后才能拿到后台的响应信息,记录日志可以弄成异步,让日志模块去消费日志记录

介绍一个你熟悉的消息中间件
常见的有rabbitMQ、rocketMQ、Kafka，轻量级的消息队列可以使用redis提供的消息队列
rabbitMQ实现了标准的AMQP协议（高级的消息队列协议）使用erlang语言开发，支持集群部署，和多种客户语言混合使用
3个重要的概念：生产者、消费者、代理
代理：rabbitMQ本身，扮演快递的角色，把消息暂存和传递
优点：
    支持持久化
    erlang语言开发，支持高并发
    支持分布式集群，支持自动选主和自动容灾
    支持多种语言
    支持消费确认，支持消息消费确认保证了每条消息可以被正常消费
    支持很多插件
消息类型
    direct：默认模式，一对一的发送模式，一条消息只发送给一个消费者
    headers：允许你匹配消息的header而非路由键
    fanout：多播，会把一个消息分发给所有的订阅者
    topic：主题订阅
如何手动实现一个消息队列和延迟消息队列
可以使用Queue来实现消息队列
Queue可以分为三大类
Deque：双端队列，Queue的子类，头部和尾部都可以插入和读取
阻塞队列：添加和删除的时候没有成功就会阻塞
非阻塞队列：直接返回操作的结果,Deque是非阻塞队列

MQ有什么作用，你都用过哪些MQ中间件
    用来削峰填谷，解决短时间内爆发式请求

MQ的特点是什么
    先进先出、发布订阅工作模式、持久化、分布式、消息确认
    MQ一个主要特征就是应对大流量、大数据的高并发环境，一个单体的MQ服务器很难应对高并发的压力的，所以MQ都支持分布式应用的部署，
    以分摊和降低高并发对中间件系统的冲击

引入MQ中间件会带来哪些问题
    增加系统的运行风险
    增加了系统的复杂性
常见的MQ中间件的优缺点分析
Redis:轻量级的消息中间件，List实现消息队列或者redis提供发布订阅，但发布订阅不支持持久化和消息确认
Kafka的吞吐量比rabbitMQ高一两个等级
Kafka有幂等性功能，而rabbitMQ没有


快速处理积压的消息
    一个消费者一秒是 1000 条，一秒 3 个消费者是 3000 条，一分钟是 18W 条，1000 多 W 条需要一个小时恢复。
    步骤：
    先修复 consumer 的问题，确保其恢复消费速度，然后将现有的 consumer 都停掉
    新建一个topic,partition是原来的 10 倍，临时建立好原先 10 倍或者 20 倍的 queue 数量
    然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，
    直接均匀轮询写入临时建立好的 10 倍数量的 queue
    接着临时征用 10 倍的机器来部署 consumer,每一批 consumer 消费一个临时 queue 的数据
    这种做法相当 于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常 10 倍速度等快速消费完积压数据之后，恢复原先部署架构 ，
    重新用原先的 consumer机器消费消息
    原来 3 个消费者需要 1 个小时可以搞定，现在 30 个临时消费者需要 10 分钟就可以搞定。
    如果用的 rabbitmq，并且设置了过期时间，如果此消费在 queue里积压超过一定的时间会被 rabbitmq清理掉，数据直接搞丢。
    这个时候开始写程序，将丢失的那批 数据查出来，然后重新灌入mq里面，把白天丢的数据补回来。
    如果消息积压mq，长时间没被处理掉，导致mq快写完满了，你临时写一个程序，接入数据来消费，写到一个临时的mq里，
    再让其他消费者慢慢消费 或者消费一个丢弃一个，都不要了，快速消费掉所有的消息，然后晚上补数据。

